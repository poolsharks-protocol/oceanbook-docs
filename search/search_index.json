{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"","title":"Home"},{"location":"docs/","text":"COMING SOON \u00b6","title":"COMING SOON"},{"location":"docs/#coming-soon","text":"","title":"COMING SOON"},{"location":"docs/fungible-queues/a-technical-history/","text":"Apache Kafka: Scalable Real-Time Data Feeds \u00b6 To understand the principal motivation behind Fungible Queues and why they work, let's look to message queue architecture from previous generations. Apache Kafka was created by a team led by Jay Kreps, Jun Rao, and Neha Narkhede at LinkedIn in 2010. Kafka\u2019s architecture was built with the ability to handle billions of individual events in mind with varying sizes. To understand Apache Kafka Queues we should know the relevant concepts: Topics Offsets In the above figure, a Topic is simply a log of events . In our case, each event represents an individual Order . Thus, events 1 through 100 can each represent an Order each with differing sizes. A Topic here can be equated to a Page in each Book contract. When you write a new event to the Topic , it always goes on the end. Each Topic maintains an Offset which will always tell which events have already been processed. This allows Kafka to obey the principle of Exactly-Once Processing . While we only have synchronous processing in the context of a blockchain, this concept of an Offset does allow us to tell Producers , otherwise known as Market Makers in the context of orderbooks, when their Order has been filled. The Offset in the context of OceanBook simply plays the role of tracking how much volume has occurred on a given Page and relating that to the point where the Market Maker pushed their Order to the queue.","title":"A Technical History"},{"location":"docs/fungible-queues/a-technical-history/#apache-kafka-scalable-real-time-data-feeds","text":"To understand the principal motivation behind Fungible Queues and why they work, let's look to message queue architecture from previous generations. Apache Kafka was created by a team led by Jay Kreps, Jun Rao, and Neha Narkhede at LinkedIn in 2010. Kafka\u2019s architecture was built with the ability to handle billions of individual events in mind with varying sizes. To understand Apache Kafka Queues we should know the relevant concepts: Topics Offsets In the above figure, a Topic is simply a log of events . In our case, each event represents an individual Order . Thus, events 1 through 100 can each represent an Order each with differing sizes. A Topic here can be equated to a Page in each Book contract. When you write a new event to the Topic , it always goes on the end. Each Topic maintains an Offset which will always tell which events have already been processed. This allows Kafka to obey the principle of Exactly-Once Processing . While we only have synchronous processing in the context of a blockchain, this concept of an Offset does allow us to tell Producers , otherwise known as Market Makers in the context of orderbooks, when their Order has been filled. The Offset in the context of OceanBook simply plays the role of tracking how much volume has occurred on a given Page and relating that to the point where the Market Maker pushed their Order to the queue.","title":"Apache Kafka: Scalable Real-Time Data Feeds"},{"location":"docs/fungible-queues/for-market-makers/","text":"For Market Makers \u00b6","title":"For Market Makers"},{"location":"docs/fungible-queues/for-market-makers/#for-market-makers","text":"","title":"For Market Makers"},{"location":"docs/fungible-queues/","text":"Introduction \u00b6 What Is a Fungible Queue? \u00b6 Fungible Queues provide a means of telling Market Makers, also referred to as Liquidity Setters, when their order is filled. They are developed with the quality of fungilibity in mind, meaning that all the assets being placed onto the same queue are treated in an equal manner. This data structure helps us achieve the quality of \"price time priority\" wherein each Market Maker has a queue position. See References on why queue position in a limit order book matters. In the end we only need a few pieces of information to have an operational Maker/Taker side: the exchange rate for the specific queue the total volume of maker orders created the total volume of taker orders executed When things are of a homogenous nature in a smart contract, there is no need for us to read multiple pieces of data. Thus... If we are aware of how much liquidity is available at a certain price on a token pair, there is no need to read each individual maker order. This is what makes the concept of Fungible Queues unique.","title":"Intro"},{"location":"docs/fungible-queues/#introduction","text":"","title":"Introduction"},{"location":"docs/fungible-queues/#what-is-a-fungible-queue","text":"Fungible Queues provide a means of telling Market Makers, also referred to as Liquidity Setters, when their order is filled. They are developed with the quality of fungilibity in mind, meaning that all the assets being placed onto the same queue are treated in an equal manner. This data structure helps us achieve the quality of \"price time priority\" wherein each Market Maker has a queue position. See References on why queue position in a limit order book matters. In the end we only need a few pieces of information to have an operational Maker/Taker side: the exchange rate for the specific queue the total volume of maker orders created the total volume of taker orders executed When things are of a homogenous nature in a smart contract, there is no need for us to read multiple pieces of data. Thus... If we are aware of how much liquidity is available at a certain price on a token pair, there is no need to read each individual maker order. This is what makes the concept of Fungible Queues unique.","title":"What Is a Fungible Queue?"},{"location":"docs/fungible-queues/the-simple-explanation/","text":"Let's imagine a 1L bottle of water which is marked every 100 mL. Alice has Mineral Water and wants Spring Water. Bob has Spring Water and wants Mineral Water. Both are willing to exchange 100 mL for 100 mL. These steps must take place in the following order: Alice puts the Mineral Water bottle from 0 mL to 100 mL. Bob comes and takes the 100 mL of Mineral Water Alice placed. At the same time, he will place his 100 mL of Spring Water in a second bottle. Alice can then claim her 100 mL of Spring Water. Alice is able to claim the output of her order fill since 100 mL of Spring Water was taken. Since the exchange took place at a 1:1 rate, Alice will be able to claim 100 mL of Spring Water. The smallest possible amount Bob can take will depend of the precision of our liquid measurements. If that amount is 1 mL, there can be a maximum of 100 individual exchanges for Alice's 100 mL. Each time the person taking Mineral Water will have to update how much was taken in total. A bottle will hereafter be referred to as a Page , which is a collection of orders at the same price point.","title":"The Simple Explanation"},{"location":"docs/intro/","text":"Introduction \u00b6 What is OceanBook? \u00b6 The OceanBook protocol is a peer-to-peer decentralized exchange which introduces efficient price time priority into the world of decentralized exchanges. It is built for fully fungible ERC-20 token exchange on EVM-compatible blockchains and meant to function as an on-chain limit order book . OceanBook has three main components: OrderBook an on-chain representation of the liquidity in each Page (see core concepts) Matching engine the smart contract code to first prioritze price and then time Router the means by which maker and taker orders will be sent to the appropriate Book contract Mistakes of the Past: Where Decentralized Orderbooks Have Fallen Short \u00b6 There is one guiding principle which sets OceanBook apart from other on-chain orderbook protocols: For X amount of gas spent, a taker must receive Y liquidity. Maker OTC by the Dai Foundation \u00b6 Maker OTC was an attempt at an on-chain orderbook with the following in its README.md : Design Consideration The protocol uses on-chain order book and matching engine. The primary advantage of such approach is that the liquidity is avaiable for other smart contracts that can access it in one atomic ethereum transaction. The second advantage is that the protocol is fully decentralized without any need for an operator. Order book for each market is implemented as two double-linked sorted lists, one for each side of the market. At any one time the list should be sorted. The second important design choice is the use of the Escrow model for Makers - every order on the order book needs to be \"backed up\" by the liquidity that is escrowed in the contract. Although such approach locks down liquidity, it guarantees zero-risk, instantenous settlement. The main downfalls of Maker OTC: Offer iteration is expensive Doubly linked list maintenance Each offer has a fragmentation of the liquidity at a given price. Instead of aggregating all the orders at a given price, we have to do N loads. This N value could be unbounded. Thus, markets could be disrupted by extreme liquidity fragmentation. All it would take is the placement of thousands of small offers. CONCLUSION: The taker is not guaranteed to spend X gas for Y liquidity. 1inch Limit Order Protocol by the 1inch Labs \u00b6 The 1inch Limit Order Protocol is vastly different in design in that the limit order book is stored off-chain. This section will also address the majority of Orderbook DEXes, which are currently off-chain due to the benefit of free order placement as well as the difficulty of maintaining contract state. Contract allows users to place limit orders, that later could be filled on-chain. Limit order itself is a data structure created off-chain and signed according to EIP-712. The main downfalls of 1inch Limit Order Protocol: Liquidity fragmentation between signed messages No escrow = no guaranteed liquidity Proprietary off-chain orderbook Every signed message (i.e. a single limit order) will cost ~4000 gas if the message contains 64 bytes of data. This means we again arrive at the issue of liquidity fragmentation where the amount of gas to get Y liquidity is unknown. One of the downsides of off-chain orderbooks is the inability to bid a higher gas price to have one's transaction prioritized. In addition, the internals of the off-chain orderbook are often proprietary, lacking transparency for users of the protocol. This leads to the same business model as what currently exists for Robinhood. \"Robinhood Markets Inc. gets about 80% of its revenue from payment for order flow, selling its customers' orders to market makers like Citadel Securities to execute them.\" Matt Levine from Bloomberg as well as many others in the space have written extensively on this, and ultimately if the data is explicitly public or explicitly private, no centralized party has proprietary access to user data. Even if off-chain orderbooks are able to achieve a fair market structure, they lack on-chain composability, guaranteed settlement, and the general 'walled garden' nature of the blockchain. CONCLUSION: The taker is not guaranteed to spend X gas for Y liquidity. How does the OceanBook protocol compare to a traditional centralized exchange orderbook? \u00b6 In comparison to a centralized exchange orderbook, on-chain limit order books cannot be equally expressive without encountering scalability issues. This is due to the limitations around how much data can be loaded within a single smart contract transaction, which is maximum ~450 kb for a single transaction. However, we want to strictly limit the amount of on-chain storage access in order to maximize volume for the benefit of everyone. Thus, one of the core driving principles in the design of the protocol is to maximize deterministic behavior. Traditionally this is why AMMs have worked quite well, and the same rules apply here. This means accomodating for trades of different sizes separately as the amount of data each of these will load can be drastically different. More details on how we solved for this will be released alongside the launch of public testnet. What will be the launch strategy? \u00b6 The protocol will be implemented as a set of non-upgradable smart contracts to enable full permissionless access and protect against censorship resistance. The smart contract code for the protocol will be open-sourced upon completion of multiple internal and external audits as well as a public testnet launch. The focus initially will be on protocols which have: - Numerous derivative tokens - Liquidity fragmentation issues - High volatility such as options tokens Areas of focus: - Foreign exchange (USDC, EUROC, etc.) - Options protocols - Sub-DAO governance tokens","title":"Overview"},{"location":"docs/intro/#introduction","text":"","title":"Introduction"},{"location":"docs/intro/#what-is-oceanbook","text":"The OceanBook protocol is a peer-to-peer decentralized exchange which introduces efficient price time priority into the world of decentralized exchanges. It is built for fully fungible ERC-20 token exchange on EVM-compatible blockchains and meant to function as an on-chain limit order book . OceanBook has three main components: OrderBook an on-chain representation of the liquidity in each Page (see core concepts) Matching engine the smart contract code to first prioritze price and then time Router the means by which maker and taker orders will be sent to the appropriate Book contract","title":"What is OceanBook?"},{"location":"docs/intro/#mistakes-of-the-past-where-decentralized-orderbooks-have-fallen-short","text":"There is one guiding principle which sets OceanBook apart from other on-chain orderbook protocols: For X amount of gas spent, a taker must receive Y liquidity.","title":"Mistakes of the Past: Where Decentralized Orderbooks Have Fallen Short"},{"location":"docs/intro/#maker-otc-by-the-dai-foundation","text":"Maker OTC was an attempt at an on-chain orderbook with the following in its README.md : Design Consideration The protocol uses on-chain order book and matching engine. The primary advantage of such approach is that the liquidity is avaiable for other smart contracts that can access it in one atomic ethereum transaction. The second advantage is that the protocol is fully decentralized without any need for an operator. Order book for each market is implemented as two double-linked sorted lists, one for each side of the market. At any one time the list should be sorted. The second important design choice is the use of the Escrow model for Makers - every order on the order book needs to be \"backed up\" by the liquidity that is escrowed in the contract. Although such approach locks down liquidity, it guarantees zero-risk, instantenous settlement. The main downfalls of Maker OTC: Offer iteration is expensive Doubly linked list maintenance Each offer has a fragmentation of the liquidity at a given price. Instead of aggregating all the orders at a given price, we have to do N loads. This N value could be unbounded. Thus, markets could be disrupted by extreme liquidity fragmentation. All it would take is the placement of thousands of small offers. CONCLUSION: The taker is not guaranteed to spend X gas for Y liquidity.","title":"Maker OTC by the Dai Foundation"},{"location":"docs/intro/#1inch-limit-order-protocol-by-the-1inch-labs","text":"The 1inch Limit Order Protocol is vastly different in design in that the limit order book is stored off-chain. This section will also address the majority of Orderbook DEXes, which are currently off-chain due to the benefit of free order placement as well as the difficulty of maintaining contract state. Contract allows users to place limit orders, that later could be filled on-chain. Limit order itself is a data structure created off-chain and signed according to EIP-712. The main downfalls of 1inch Limit Order Protocol: Liquidity fragmentation between signed messages No escrow = no guaranteed liquidity Proprietary off-chain orderbook Every signed message (i.e. a single limit order) will cost ~4000 gas if the message contains 64 bytes of data. This means we again arrive at the issue of liquidity fragmentation where the amount of gas to get Y liquidity is unknown. One of the downsides of off-chain orderbooks is the inability to bid a higher gas price to have one's transaction prioritized. In addition, the internals of the off-chain orderbook are often proprietary, lacking transparency for users of the protocol. This leads to the same business model as what currently exists for Robinhood. \"Robinhood Markets Inc. gets about 80% of its revenue from payment for order flow, selling its customers' orders to market makers like Citadel Securities to execute them.\" Matt Levine from Bloomberg as well as many others in the space have written extensively on this, and ultimately if the data is explicitly public or explicitly private, no centralized party has proprietary access to user data. Even if off-chain orderbooks are able to achieve a fair market structure, they lack on-chain composability, guaranteed settlement, and the general 'walled garden' nature of the blockchain. CONCLUSION: The taker is not guaranteed to spend X gas for Y liquidity.","title":"1inch Limit Order Protocol by the 1inch Labs"},{"location":"docs/intro/#how-does-the-oceanbook-protocol-compare-to-a-traditional-centralized-exchange-orderbook","text":"In comparison to a centralized exchange orderbook, on-chain limit order books cannot be equally expressive without encountering scalability issues. This is due to the limitations around how much data can be loaded within a single smart contract transaction, which is maximum ~450 kb for a single transaction. However, we want to strictly limit the amount of on-chain storage access in order to maximize volume for the benefit of everyone. Thus, one of the core driving principles in the design of the protocol is to maximize deterministic behavior. Traditionally this is why AMMs have worked quite well, and the same rules apply here. This means accomodating for trades of different sizes separately as the amount of data each of these will load can be drastically different. More details on how we solved for this will be released alongside the launch of public testnet.","title":"How does the OceanBook protocol compare to a traditional centralized exchange orderbook?"},{"location":"docs/intro/#what-will-be-the-launch-strategy","text":"The protocol will be implemented as a set of non-upgradable smart contracts to enable full permissionless access and protect against censorship resistance. The smart contract code for the protocol will be open-sourced upon completion of multiple internal and external audits as well as a public testnet launch. The focus initially will be on protocols which have: - Numerous derivative tokens - Liquidity fragmentation issues - High volatility such as options tokens Areas of focus: - Foreign exchange (USDC, EUROC, etc.) - Options protocols - Sub-DAO governance tokens","title":"What will be the launch strategy?"},{"location":"docs/modules/aave/","text":"Aave Module \u00b6 The Aave Module takes the same 'carpooling' approach as the GroupSwap module in terms of matching up transactions that will execute with the same parameters (i.e. Deposit, Liquidate, etc.) for saving users on gas and increasing transaction reliability. A typical Aave deposit call can easily cost upwards of 250000 gas units depending on the token, which is 2x the cost of a Uniswap V3 swap. This creates a large barrier for smaller wallets that want to earn sustainable yield from a variable lending market and restricts the movement of their capital over time.","title":"Aave Module"},{"location":"docs/modules/aave/#aave-module","text":"The Aave Module takes the same 'carpooling' approach as the GroupSwap module in terms of matching up transactions that will execute with the same parameters (i.e. Deposit, Liquidate, etc.) for saving users on gas and increasing transaction reliability. A typical Aave deposit call can easily cost upwards of 250000 gas units depending on the token, which is 2x the cost of a Uniswap V3 swap. This creates a large barrier for smaller wallets that want to earn sustainable yield from a variable lending market and restricts the movement of their capital over time.","title":"Aave Module"},{"location":"docs/modules/core/","text":"Core ERC-20 \u00b6 The core ERC-20 contract provides the base functionality required by the protocol, plus extra functions that can be utilized by modules to optimize gas usage, while still providing a full feature set of asset management. In order to add additional functionality, modules must be authorized to interact with the core ERC-20 contract functionality. This is currently managed and operated by an admin function, but could be subject to decentralized governance in the future. Check Module Authorized Status \u00b6 graph LR A[User] --->|calls| B{Module}; B --->|calls| C{Core}; C --->|checks| D[Authorized?]; D -->|Yes| C; D ---->|No| B; Authorize New Module \u00b6 graph LR A[Admin] --->|calls| B{core.updateModule}; B -->|updates| C[authorizedModules]; C --->|sets true/false| D[moduleAddress];","title":"Core ERC-20"},{"location":"docs/modules/core/#core-erc-20","text":"The core ERC-20 contract provides the base functionality required by the protocol, plus extra functions that can be utilized by modules to optimize gas usage, while still providing a full feature set of asset management. In order to add additional functionality, modules must be authorized to interact with the core ERC-20 contract functionality. This is currently managed and operated by an admin function, but could be subject to decentralized governance in the future.","title":"Core ERC-20"},{"location":"docs/modules/core/#check-module-authorized-status","text":"graph LR A[User] --->|calls| B{Module}; B --->|calls| C{Core}; C --->|checks| D[Authorized?]; D -->|Yes| C; D ---->|No| B;","title":"Check Module Authorized Status"},{"location":"docs/modules/core/#authorize-new-module","text":"graph LR A[Admin] --->|calls| B{core.updateModule}; B -->|updates| C[authorizedModules]; C --->|sets true/false| D[moduleAddress];","title":"Authorize New Module"},{"location":"docs/modules/groupswap/","text":"GroupSwap Module \u00b6 GroupSwap provides the functionality of allowing users to split gas costs of an on-chain DEX swap. Once the gas tank for a pair fills up, meaning the anticipated gas cost is covered, a swap will execute on-chain. This swap execution will emit an event and redistribute the output token evenly directly based on the input token amount. [Diagram here to detail GroupSwap process] The benefits of this approach are the following: 1) Eliminate users managing complex swap parameters (e.g. slippage). 2) Scale infinitely a single on-chain transaction based on the number of user requests. 3) Reduce gas usage of users at scale by up to 80% 4) Provide a more reliable swap transaction by setting gas price on behalf of users Normally users whom have to compete for block space on a complex transaction like a swap. Instead, PoolSharks enables users to coordinate and as a result have a more reliable execution.","title":"GroupSwap Module"},{"location":"docs/modules/groupswap/#groupswap-module","text":"GroupSwap provides the functionality of allowing users to split gas costs of an on-chain DEX swap. Once the gas tank for a pair fills up, meaning the anticipated gas cost is covered, a swap will execute on-chain. This swap execution will emit an event and redistribute the output token evenly directly based on the input token amount. [Diagram here to detail GroupSwap process] The benefits of this approach are the following: 1) Eliminate users managing complex swap parameters (e.g. slippage). 2) Scale infinitely a single on-chain transaction based on the number of user requests. 3) Reduce gas usage of users at scale by up to 80% 4) Provide a more reliable swap transaction by setting gas price on behalf of users Normally users whom have to compete for block space on a complex transaction like a swap. Instead, PoolSharks enables users to coordinate and as a result have a more reliable execution.","title":"GroupSwap Module"},{"location":"docs/modules/","text":"Modules \u00b6 The DCEX design supports modularity, this table lists all the modules Layers Module Name Short Description Status Core Handles the core functionality of tokens, handles basic user token management Authorized PredaDex Provides a fast way for a user to perform a swap on a given list of DEXes Development Group Swap Provides a way for multiple users to perform a common swap, reduces gas spent per user Development Order Book Provides a cheap way for users to have Peer-2-Peer swaps, offers a way for non-DCEX users to also interact with the liquidity inside Development Aave Provides an option for users to perform common actions like deposit, can reduce gas spent per user Development","title":"Modules"},{"location":"docs/modules/#modules","text":"The DCEX design supports modularity, this table lists all the modules Layers Module Name Short Description Status Core Handles the core functionality of tokens, handles basic user token management Authorized PredaDex Provides a fast way for a user to perform a swap on a given list of DEXes Development Group Swap Provides a way for multiple users to perform a common swap, reduces gas spent per user Development Order Book Provides a cheap way for users to have Peer-2-Peer swaps, offers a way for non-DCEX users to also interact with the liquidity inside Development Aave Provides an option for users to perform common actions like deposit, can reduce gas spent per user Development","title":"Modules"},{"location":"docs/modules/orderbook/","text":"Orderbook Module \u00b6 The Orderbook Module functions as a list of buy and sell orders earmarked at a specific price. Compared to an AMM, this model leads to a better price discovery due to the non-passive nature of market activity. Within the PoolSharks Protocol, orders are submitted on-chain. Once picked up by an Indexer on The Graph Network, the Subgraph attempts to match the user's order with another existing order. In the case there is no match, the order is left in the orderbook to be filled by another incoming order. You can follow the process for handling incoming orders below: [DIAGRAM HERE TO ILLUSTRATE ORDERBOOK PROCESS]","title":"Orderbook Module"},{"location":"docs/modules/orderbook/#orderbook-module","text":"The Orderbook Module functions as a list of buy and sell orders earmarked at a specific price. Compared to an AMM, this model leads to a better price discovery due to the non-passive nature of market activity. Within the PoolSharks Protocol, orders are submitted on-chain. Once picked up by an Indexer on The Graph Network, the Subgraph attempts to match the user's order with another existing order. In the case there is no match, the order is left in the orderbook to be filled by another incoming order. You can follow the process for handling incoming orders below: [DIAGRAM HERE TO ILLUSTRATE ORDERBOOK PROCESS]","title":"Orderbook Module"},{"location":"docs/modules/predadex/","text":"PredaDex Module \u00b6 The PredaDex module gives users a way to perform a swap request though PredaDex, which is a full on-chain DEX aggregator, thus allowing users to set their own parameters for a swap on a list of community-selected DEXes. The cost of this method is greater than that of a normal user performing a swap with the DEX directly because there is an increased cost to perform the request on top of performing the swap call. It is recommended for the average user to utilize either GroupSwap or the OrderBook module for increased reliability and gas-saving benefits. The gas costs will be slightly higher due to the Gelato execution fee of 10-15% plus the cost of making the request.","title":"PredaDex Module"},{"location":"docs/modules/predadex/#predadex-module","text":"The PredaDex module gives users a way to perform a swap request though PredaDex, which is a full on-chain DEX aggregator, thus allowing users to set their own parameters for a swap on a list of community-selected DEXes. The cost of this method is greater than that of a normal user performing a swap with the DEX directly because there is an increased cost to perform the request on top of performing the swap call. It is recommended for the average user to utilize either GroupSwap or the OrderBook module for increased reliability and gas-saving benefits. The gas costs will be slightly higher due to the Gelato execution fee of 10-15% plus the cost of making the request.","title":"PredaDex Module"},{"location":"docs/orderbook/","text":"PoolSharks Orderbook \u00b6 The PoolSharks Orderbook is an on-chain central limit order book (CLOB) on Ethereum which provides an order-matching system built for everyone.Through it's permissionless nature, users can launch a pair with no upfront capital, since there is no AMM Liquidity Pool required. More importantly the gas costs associated with creating a new pair are reduced by more than 90% due to the minimalistic and optimal on-chain storage approach. Features \u00b6 Zero off-chain execution for basic limit orders Composable multi-hop trades between multiple pairs Advanced order types and features (stop loss, trailing take profit, flash crash protection, etc. via Gelato) Seamless IDO / token launches without upfront capital at a specified price Design \u00b6 [Diagram] Here are some base definitions to better help convey the design. Book: A collection of Pages regarding to a monodirectional token pair A->B Page: A collection of orders at a given price point Orders: Description of a given user's trade Pages are doubly linked list, such that you can read through the book in a given order Orders are doubly linked lists, such that you can define who receives a trade based on volume. When an order is fulfilled, the taker spends X amount of Token A and receives Y amount of Token B, while the maker can redeem the token at a later point in time, or use it to create a new order without redeeming!","title":"PoolSharks Orderbook"},{"location":"docs/orderbook/#poolsharks-orderbook","text":"The PoolSharks Orderbook is an on-chain central limit order book (CLOB) on Ethereum which provides an order-matching system built for everyone.Through it's permissionless nature, users can launch a pair with no upfront capital, since there is no AMM Liquidity Pool required. More importantly the gas costs associated with creating a new pair are reduced by more than 90% due to the minimalistic and optimal on-chain storage approach.","title":"PoolSharks Orderbook"},{"location":"docs/orderbook/#features","text":"Zero off-chain execution for basic limit orders Composable multi-hop trades between multiple pairs Advanced order types and features (stop loss, trailing take profit, flash crash protection, etc. via Gelato) Seamless IDO / token launches without upfront capital at a specified price","title":"Features"},{"location":"docs/orderbook/#design","text":"[Diagram] Here are some base definitions to better help convey the design. Book: A collection of Pages regarding to a monodirectional token pair A->B Page: A collection of orders at a given price point Orders: Description of a given user's trade Pages are doubly linked list, such that you can read through the book in a given order Orders are doubly linked lists, such that you can define who receives a trade based on volume. When an order is fulfilled, the taker spends X amount of Token A and receives Y amount of Token B, while the maker can redeem the token at a later point in time, or use it to create a new order without redeeming!","title":"Design"},{"location":"docs/queued-market-making/","text":"QMM Core Concepts \u00b6 Queued Market Makers differ from other decentralized exchange models in that they have a split buy and sell side. Each Book contract is composed of the following: Two lists of Pages one for each trading direction A set of Orders each order is mapped to a Page A Page is a Fungible Queue which contains the following items: - Price - This is used to determine exchange rate between `Makers` and `Takers` - Volume counter - In the smart contracts, this will be referred to as `currentOffset` - This is used to track which `Maker` orders have been filled - When `Makers` go to claim and/or replace their order, this value will be checked - Example: `currentOffset` is halfway between `start` and `end` of `Maker` order and therefore 50% of their order will be claimable along with fees. - Next page - The identifier for the next lowest-priced page - Previous page - The identifier for the previous lowest-priced page - Cancel list - Cancels function as someone stepping out of the queue - These are checked for on each `Taker` order - More details on how these are handled will be released upon public testnet launch - Current estimated costs is 31,000 gas + ERC20 transfer cost","title":"QMM Core Concepts"},{"location":"docs/queued-market-making/#qmm-core-concepts","text":"Queued Market Makers differ from other decentralized exchange models in that they have a split buy and sell side. Each Book contract is composed of the following: Two lists of Pages one for each trading direction A set of Orders each order is mapped to a Page A Page is a Fungible Queue which contains the following items: - Price - This is used to determine exchange rate between `Makers` and `Takers` - Volume counter - In the smart contracts, this will be referred to as `currentOffset` - This is used to track which `Maker` orders have been filled - When `Makers` go to claim and/or replace their order, this value will be checked - Example: `currentOffset` is halfway between `start` and `end` of `Maker` order and therefore 50% of their order will be claimable along with fees. - Next page - The identifier for the next lowest-priced page - Previous page - The identifier for the previous lowest-priced page - Cancel list - Cancels function as someone stepping out of the queue - These are checked for on each `Taker` order - More details on how these are handled will be released upon public testnet launch - Current estimated costs is 31,000 gas + ERC20 transfer cost","title":"QMM Core Concepts"},{"location":"docs/queued-market-making/mev-related-risks/","text":"","title":"Mev related risks"},{"location":"docs/queued-market-making/set-liquidity/","text":"Queued Market Making \u00b6 Queueing Orders \u00b6 A Queued Market Maker is a decentralized exchange structure wherein Fungible Queues are used to achieve price time priority . The Fungible Queues , or Pages , are ordered from lowest to highest price so Takers seeking to access liquidity from the exchange can be filled up to their limit price. Each Page has a collection of Orders linked to it. In the above figure, each person will represent a Maker order in a queue. Based on a volume counter, referred to as currentOffset , we can determine which Maker orders have been filled. At the start, let's ignore Takers so we can exclusively focus on how Maker orders enter the queue. Alice has the first Order in the 4000 DAI : 1 ETH Page will starts at 0 and ends at 100 . Bob has the first Order in the 3000 DAI : 1 ETH Page will starts at 0 and ends at 100 . Carol now has three choices as a Maker with order size 100 : - Enter the queue behind Alice in the 4000 DAI page from 100 to 200 - Enter the queue behind Bob in the 3000 DAI page from 100 to 200 - Enter the queue in a new Page at another DAI price from 0 to 100 If Carol creates a Page for less than 3000 DAI : 1 ETH, her liquidity will receive priority over Alice and Bob when Takers fill orders. Since a page exists for 3000 DAI (i.e. a lower offer), the volume counter for the 4000 DAI page will remain 0 until all the orders from the 3000 DAI page are filled. The benefit in this exchange model from the perspective of Market Makers can be summarized in a few key points: 1. Fees are NOT shared with liquidity providers that provide more liquidity than is needed to fill Taker orders. 2. Since Makers are filled FIFO, they can claim their completed order immediately along with any fees generated from the order flow. This allows for subsidization of the next set of orders placed on the exchange. 3. In order for another Market Maker to front-run an existing Order, they must offer a lower price and take a loss on any liquidity provided.","title":"For Market Makers"},{"location":"docs/queued-market-making/set-liquidity/#queued-market-making","text":"","title":"Queued Market Making"},{"location":"docs/queued-market-making/set-liquidity/#queueing-orders","text":"A Queued Market Maker is a decentralized exchange structure wherein Fungible Queues are used to achieve price time priority . The Fungible Queues , or Pages , are ordered from lowest to highest price so Takers seeking to access liquidity from the exchange can be filled up to their limit price. Each Page has a collection of Orders linked to it. In the above figure, each person will represent a Maker order in a queue. Based on a volume counter, referred to as currentOffset , we can determine which Maker orders have been filled. At the start, let's ignore Takers so we can exclusively focus on how Maker orders enter the queue. Alice has the first Order in the 4000 DAI : 1 ETH Page will starts at 0 and ends at 100 . Bob has the first Order in the 3000 DAI : 1 ETH Page will starts at 0 and ends at 100 . Carol now has three choices as a Maker with order size 100 : - Enter the queue behind Alice in the 4000 DAI page from 100 to 200 - Enter the queue behind Bob in the 3000 DAI page from 100 to 200 - Enter the queue in a new Page at another DAI price from 0 to 100 If Carol creates a Page for less than 3000 DAI : 1 ETH, her liquidity will receive priority over Alice and Bob when Takers fill orders. Since a page exists for 3000 DAI (i.e. a lower offer), the volume counter for the 4000 DAI page will remain 0 until all the orders from the 3000 DAI page are filled. The benefit in this exchange model from the perspective of Market Makers can be summarized in a few key points: 1. Fees are NOT shared with liquidity providers that provide more liquidity than is needed to fill Taker orders. 2. Since Makers are filled FIFO, they can claim their completed order immediately along with any fees generated from the order flow. This allows for subsidization of the next set of orders placed on the exchange. 3. In order for another Market Maker to front-run an existing Order, they must offer a lower price and take a loss on any liquidity provided.","title":"Queueing Orders"},{"location":"docs/queued-market-making/traders/","text":"","title":"Traders"},{"location":"docs/references/automated-market-makers/","text":"Automated Market Makers \u00b6 Impermanent Loss and Price Discovery: Are Automated Market Makers a Sustainable Exchange Model? - by Jonathan Choong Bachelor of Business (Honours), UTS Business School","title":"Automated Market Makers"},{"location":"docs/references/automated-market-makers/#automated-market-makers","text":"Impermanent Loss and Price Discovery: Are Automated Market Makers a Sustainable Exchange Model? - by Jonathan Choong Bachelor of Business (Honours), UTS Business School","title":"Automated Market Makers"},{"location":"docs/references/limit-order-books/","text":"Limit Order Books \u00b6 The Value of Queue Position in a Limit Order Book - by Ciamac C. Moallemi and Kai Yuan; Columbia University Graduate School of Business Trading Fees and Efficiency in Limit Order Markets - Centre for Economic Policy Research Optimal Auction Duration: A price formation viewpoint - Ecole Polytechnique, CMAP An Open-Source Limit-Order-Book Exchange for Teaching and Research - Dave Cliff, Dept. of Computer Science, University of Bristol Is the Electronic Open Limit Order Book Inevitable? - Lawrence R. Glosten, The Journal of Finance Limit Order Book Transparency, Execution Risk, and Market Liquidity - School of Business, University of Sydney Limit orders and slippage resistance in x*y=k market makers - Hayden Adams, Uniswap Labs Token sales and shorting - Vitalik Buterin, Ethereum Foundation","title":"Limit Order Books"},{"location":"docs/references/limit-order-books/#limit-order-books","text":"The Value of Queue Position in a Limit Order Book - by Ciamac C. Moallemi and Kai Yuan; Columbia University Graduate School of Business Trading Fees and Efficiency in Limit Order Markets - Centre for Economic Policy Research Optimal Auction Duration: A price formation viewpoint - Ecole Polytechnique, CMAP An Open-Source Limit-Order-Book Exchange for Teaching and Research - Dave Cliff, Dept. of Computer Science, University of Bristol Is the Electronic Open Limit Order Book Inevitable? - Lawrence R. Glosten, The Journal of Finance Limit Order Book Transparency, Execution Risk, and Market Liquidity - School of Business, University of Sydney Limit orders and slippage resistance in x*y=k market makers - Hayden Adams, Uniswap Labs Token sales and shorting - Vitalik Buterin, Ethereum Foundation","title":"Limit Order Books"},{"location":"intro/conclusion/","text":"Conclusion \u00b6","title":"Conclusion"},{"location":"intro/conclusion/#conclusion","text":"","title":"Conclusion"},{"location":"intro/","text":"Introduction \u00b6 What is OceanBook? \u00b6 PoolSharks OceanBook aims to deliver a fully on-chain FIFO matching engine for limit orders, which is gas finite and optimized to be fully viable on L1 Ethereum Mainnet. To fully understand what OceanBook proposes, we have to understand the markets, how an Orderbook works, and what the tradeoffs are versus an Automated Market Maker (AMM). After we're aware of the differences for both traders and LPs, we can start to comprehend where this new market maker model really shines. Current Decentralized Exchanges \u00b6 Solution B \u00b6 It may sacrifice decentralization to negate the gas of a sub-chain by utilizing events mixed with off-chain bots to relay back on-chain when conditions are met. The most obvious example of this is a centralized exchange like Binance or Coinbase, you interact with their service through an API, all balances are stored in shared wallets where the keys are unknown to the end user, and each individual user\u2019s balance is known through tracking token deposits and spends which are then stored in some database. But all execution that needs to happen, will be executed on the relevant chain. Solution DCEX \u00b6 By combining the previous solutions ideas into a new model, we are able to have the ambiguity of full decentralization, execution being requested then executed on the relevant chain, and minimal costs (compared to current on-chain solutions). Since the solution is a combination of the above, it also shares some of the pros and cons of the above, to use the protocol you have to deposit into the contract, similar to Solution B . It utilizes a decentralized indexing service, The Graph, whereas Solution A utilizes sub-chains, but these are used in quite similar ways. The base actions required to interact with a DCEX protocol are as follows: Optional: Deposit ERC-20 token into the DCEX-ERC20-Core contract via deposit(address depositToken, uint256 depositAmount) When depositing ETH, utilize msg.value along with any other token you wish to deposit. Make an action request, either through a Module or through the Core For example, you want to Transfer DAI to your friend, you can call the core\u2019s transfer(address transferToken, uint256 transferAmount, address receiver) function, if the receiver doesn't have an account it will create one for them, thus allowing the receiver to \u2018 redeem \u2019 their token simply by using the DCEX protocol, or withdrawing to an external address [Diagram of DCEX hierarchy]","title":"Introduction"},{"location":"intro/#introduction","text":"","title":"Introduction"},{"location":"intro/#what-is-oceanbook","text":"PoolSharks OceanBook aims to deliver a fully on-chain FIFO matching engine for limit orders, which is gas finite and optimized to be fully viable on L1 Ethereum Mainnet. To fully understand what OceanBook proposes, we have to understand the markets, how an Orderbook works, and what the tradeoffs are versus an Automated Market Maker (AMM). After we're aware of the differences for both traders and LPs, we can start to comprehend where this new market maker model really shines.","title":"What is OceanBook?"},{"location":"intro/#current-decentralized-exchanges","text":"","title":"Current Decentralized Exchanges"},{"location":"intro/#solution-b","text":"It may sacrifice decentralization to negate the gas of a sub-chain by utilizing events mixed with off-chain bots to relay back on-chain when conditions are met. The most obvious example of this is a centralized exchange like Binance or Coinbase, you interact with their service through an API, all balances are stored in shared wallets where the keys are unknown to the end user, and each individual user\u2019s balance is known through tracking token deposits and spends which are then stored in some database. But all execution that needs to happen, will be executed on the relevant chain.","title":"Solution B"},{"location":"intro/#solution-dcex","text":"By combining the previous solutions ideas into a new model, we are able to have the ambiguity of full decentralization, execution being requested then executed on the relevant chain, and minimal costs (compared to current on-chain solutions). Since the solution is a combination of the above, it also shares some of the pros and cons of the above, to use the protocol you have to deposit into the contract, similar to Solution B . It utilizes a decentralized indexing service, The Graph, whereas Solution A utilizes sub-chains, but these are used in quite similar ways. The base actions required to interact with a DCEX protocol are as follows: Optional: Deposit ERC-20 token into the DCEX-ERC20-Core contract via deposit(address depositToken, uint256 depositAmount) When depositing ETH, utilize msg.value along with any other token you wish to deposit. Make an action request, either through a Module or through the Core For example, you want to Transfer DAI to your friend, you can call the core\u2019s transfer(address transferToken, uint256 transferAmount, address receiver) function, if the receiver doesn't have an account it will create one for them, thus allowing the receiver to \u2018 redeem \u2019 their token simply by using the DCEX protocol, or withdrawing to an external address [Diagram of DCEX hierarchy]","title":"Solution DCEX"},{"location":"intro/security/","text":"Security \u00b6","title":"Security"},{"location":"intro/security/#security","text":"","title":"Security"},{"location":"intro/layers/code-storage/","text":"Trustless Code Storage \u00b6 What It Does \u00b6 The code storage layer directly relates to the execution layer . The code that the execution layer uses exists on IPFS, which is immutable, the IPFS hash resolves to a precompiled AssemblyScript file, compiled into Wasm binary instructions which can then be executed on. [DIAGRAM HERE: SHOWING RETRIEVAL OF POLYWRAP RESOLVER FROM IPFS]","title":"Trustless Code Storage"},{"location":"intro/layers/code-storage/#trustless-code-storage","text":"","title":"Trustless Code Storage"},{"location":"intro/layers/code-storage/#what-it-does","text":"The code storage layer directly relates to the execution layer . The code that the execution layer uses exists on IPFS, which is immutable, the IPFS hash resolves to a precompiled AssemblyScript file, compiled into Wasm binary instructions which can then be executed on. [DIAGRAM HERE: SHOWING RETRIEVAL OF POLYWRAP RESOLVER FROM IPFS]","title":"What It Does"},{"location":"intro/layers/execution/","text":"Execution \u00b6 What It Does \u00b6 Execution on-chain is required to reflect any requests users make on-chain. In the case of the GroupSwap feature, multiple users come together to fill a gas tank for a single swap on-chain. Example graph LR A[Gelato Bot] -->|Pull Code from IPFS| B[IPFS] B -->|Call to Query Layer| C{{Query Layer}}; C -->|Execution Needed?| D[Call On Chain Function]; C -->|No Execution Needed?| E[return]; The actions taken on-chain utilize data from The Graph Network. This data connection is made possible by Polywrap resolvers that run on Gelato Network nodes and query data from The Graph. Polywrap resolvers have a basic true/false 'checker' function that is run to determine if anything needs to be done on-chain. For example, if a gas tank is full for a given swap pair, a swap will be executed on-chain and the output token will be distributed evenly amongst the participants based on the amount of input token they contributed to the pool. Example graph TD A[Gelato Bot] -->|Pull Code from IPFS| B[IPFS] B -->|Call to Query Layer| C{{Query Layer}}; C -->|Gas Tank Full?| D[Call On Chain Function]; C -->|Gas Tank Not Full?| E[return]; D -->|Swap Happens| F[Emit event that states swap happened]; [DIAGRAM HERE: SHOWING DISTRIBUTION OF OUTPUT TOKEN IN THE GRAPH] The PoolSharks Team has built a DEX aggregator that will handle the liquidity sourcing in the case of the GroupSwap feature. As more features are integrated with the PoolSharks Protocol, more contracts will be required for the purposes of routing common requests on-chain and finding the most cost-effective path. Abstraction \u00b6 The Execution Layer abstracts away users having to set their own gas price. Currently this gas price is set by Gelato. The PoolSharks Team is exploring leveraging of data to set other parameters such as slippage on behalf of users. User Functionality \u00b6 The Gelato Network will enable asset transfer to be automated either on behalf of a user or a set of user requests. Withdraws will be processed in this manner where a withdraw request is submitted and then finalized on-chain once processed by a Gelato Polywrap bot. Trustless data is a key factor here to ensure the data being served matches what users submitted on-chain. Routing requests to other on-chain protocols is also handled by Gelato Polywrap bots, such as in the case of a Uniswap swap or an Aave deposit call. Events are then emitted from the resulting on-chain action and then reflected back in the Core ERC20 Subgraph for syncing purposes. Production Requirements \u00b6 Currently, anyone can create a task for a smart contract function that is executable by the Gelato Network. However, in our case we need to limit execution of our Core ERC20 contract functions to whitelisted modules only. Certainly we don't 'Bob down the street' executing our smart contract functions and passing bad data. Additionally, the protocol will ideally deploy immutable Gelato tasks in an effort to make the system behave more like a smart contract. Censorship resistance, immutability, and non-custodial are all descriptors we intend to reflect in the design of this protocol.","title":"Execution"},{"location":"intro/layers/execution/#execution","text":"","title":"Execution"},{"location":"intro/layers/execution/#what-it-does","text":"Execution on-chain is required to reflect any requests users make on-chain. In the case of the GroupSwap feature, multiple users come together to fill a gas tank for a single swap on-chain. Example graph LR A[Gelato Bot] -->|Pull Code from IPFS| B[IPFS] B -->|Call to Query Layer| C{{Query Layer}}; C -->|Execution Needed?| D[Call On Chain Function]; C -->|No Execution Needed?| E[return]; The actions taken on-chain utilize data from The Graph Network. This data connection is made possible by Polywrap resolvers that run on Gelato Network nodes and query data from The Graph. Polywrap resolvers have a basic true/false 'checker' function that is run to determine if anything needs to be done on-chain. For example, if a gas tank is full for a given swap pair, a swap will be executed on-chain and the output token will be distributed evenly amongst the participants based on the amount of input token they contributed to the pool. Example graph TD A[Gelato Bot] -->|Pull Code from IPFS| B[IPFS] B -->|Call to Query Layer| C{{Query Layer}}; C -->|Gas Tank Full?| D[Call On Chain Function]; C -->|Gas Tank Not Full?| E[return]; D -->|Swap Happens| F[Emit event that states swap happened]; [DIAGRAM HERE: SHOWING DISTRIBUTION OF OUTPUT TOKEN IN THE GRAPH] The PoolSharks Team has built a DEX aggregator that will handle the liquidity sourcing in the case of the GroupSwap feature. As more features are integrated with the PoolSharks Protocol, more contracts will be required for the purposes of routing common requests on-chain and finding the most cost-effective path.","title":"What It Does"},{"location":"intro/layers/execution/#abstraction","text":"The Execution Layer abstracts away users having to set their own gas price. Currently this gas price is set by Gelato. The PoolSharks Team is exploring leveraging of data to set other parameters such as slippage on behalf of users.","title":"Abstraction"},{"location":"intro/layers/execution/#user-functionality","text":"The Gelato Network will enable asset transfer to be automated either on behalf of a user or a set of user requests. Withdraws will be processed in this manner where a withdraw request is submitted and then finalized on-chain once processed by a Gelato Polywrap bot. Trustless data is a key factor here to ensure the data being served matches what users submitted on-chain. Routing requests to other on-chain protocols is also handled by Gelato Polywrap bots, such as in the case of a Uniswap swap or an Aave deposit call. Events are then emitted from the resulting on-chain action and then reflected back in the Core ERC20 Subgraph for syncing purposes.","title":"User Functionality"},{"location":"intro/layers/execution/#production-requirements","text":"Currently, anyone can create a task for a smart contract function that is executable by the Gelato Network. However, in our case we need to limit execution of our Core ERC20 contract functions to whitelisted modules only. Certainly we don't 'Bob down the street' executing our smart contract functions and passing bad data. Additionally, the protocol will ideally deploy immutable Gelato tasks in an effort to make the system behave more like a smart contract. Censorship resistance, immutability, and non-custodial are all descriptors we intend to reflect in the design of this protocol.","title":"Production Requirements"},{"location":"intro/layers/","text":"Layers \u00b6 The DCEX design consists of 5 seperate layers, all intended to work together in an attempt to provide a fully decentralized execution loop, reduce user consumed gas, and present new ways to perform complex and costly tasks by utilizing code execution off-chain Layers Layer Short Description User Interaction info Data Ingestion info Data Queries info On Chain Execution info Code Stoarge info","title":"Layers"},{"location":"intro/layers/#layers","text":"The DCEX design consists of 5 seperate layers, all intended to work together in an attempt to provide a fully decentralized execution loop, reduce user consumed gas, and present new ways to perform complex and costly tasks by utilizing code execution off-chain Layers Layer Short Description User Interaction info Data Ingestion info Data Queries info On Chain Execution info Code Stoarge info","title":"Layers"},{"location":"intro/layers/ingestion/","text":"Data Ingestion \u00b6 What It Does \u00b6 Once events occur on-chain, the Core ERC20 Subgraph receives record of what happened and reflects those changes via event handlers. For example, in the case of a Deposit event, the following event is emitted: Deposit (address user, address token, uint256 amount) The Deposit handler will assign the balance amount to the account user for the contract address token . Example graph LR A[Deposit Event] --> B{{Deposit Handler}}; B -->|Validates Data| C[(<br/>+User Balance)]; The balance is now spendable by the user, meaning they can request a withdraw, groupswap, etc. Once spendable balance has been associated with a user request, the balance will be made nonspendable in the amount requested by the user. This prevents the classical double-spending problem from occurring. Example graph LR A[GroupSwap Event] --> B{{GroupSwap Handler}}; B -->|Validates Data| C[(<br/>-unreservedBalance<br/>+reservedBalance)]; In our system design, we typically refer to this process as making a reservation . Balance is nonspendable until the order is cancelled by the user or the order is fulfilled. Abstraction \u00b6 Here the Core ERC20 Subgraph is abstracting away the costs of storing all the accounting and user request information on-chain and instead opting for the data to be availalble via The Graph Network. Production Requirements \u00b6 Indexing speed here is a potential issue, however Ethereum is limited to 15 TPS which bottlenecks the amount of events the DCEX Subgraphs will be processing. One solution here is to have the team run its own node within The Graph Network, which will to a large guarantee real-time availability of Subgraph data. The other potential pitfall is indexing correctness, for which a process needs to be developed around creating disputes for Proof of Indexing (POI) when data is indexed in an invalid manner.","title":"Data Ingestion"},{"location":"intro/layers/ingestion/#data-ingestion","text":"","title":"Data Ingestion"},{"location":"intro/layers/ingestion/#what-it-does","text":"Once events occur on-chain, the Core ERC20 Subgraph receives record of what happened and reflects those changes via event handlers. For example, in the case of a Deposit event, the following event is emitted: Deposit (address user, address token, uint256 amount) The Deposit handler will assign the balance amount to the account user for the contract address token . Example graph LR A[Deposit Event] --> B{{Deposit Handler}}; B -->|Validates Data| C[(<br/>+User Balance)]; The balance is now spendable by the user, meaning they can request a withdraw, groupswap, etc. Once spendable balance has been associated with a user request, the balance will be made nonspendable in the amount requested by the user. This prevents the classical double-spending problem from occurring. Example graph LR A[GroupSwap Event] --> B{{GroupSwap Handler}}; B -->|Validates Data| C[(<br/>-unreservedBalance<br/>+reservedBalance)]; In our system design, we typically refer to this process as making a reservation . Balance is nonspendable until the order is cancelled by the user or the order is fulfilled.","title":"What It Does"},{"location":"intro/layers/ingestion/#abstraction","text":"Here the Core ERC20 Subgraph is abstracting away the costs of storing all the accounting and user request information on-chain and instead opting for the data to be availalble via The Graph Network.","title":"Abstraction"},{"location":"intro/layers/ingestion/#production-requirements","text":"Indexing speed here is a potential issue, however Ethereum is limited to 15 TPS which bottlenecks the amount of events the DCEX Subgraphs will be processing. One solution here is to have the team run its own node within The Graph Network, which will to a large guarantee real-time availability of Subgraph data. The other potential pitfall is indexing correctness, for which a process needs to be developed around creating disputes for Proof of Indexing (POI) when data is indexed in an invalid manner.","title":"Production Requirements"},{"location":"intro/layers/query/","text":"Database Query \u00b6 What It Does \u00b6 The query layer resolves the trustless interactions between the Execution Layer (Gelato Network) and the Data Layer (The Graph Network) and ensures data has been properly validated prior to initiating any transactions on-chain. This layer is still under heavy construction and is the primary blocker for creating a fully trustless execution loop comprised of on-chain and off-chain components. Example graph LR A[User] -->|API Call| B{{Query Layer}}; B -->|Query Subgraph| C[Decentralized Node Query]; C -->|valid zkSnark?| D[return response]; C -->|invalid zkSnark?| E[Submit Dispute]; E -->|Retry| B; Abstraction \u00b6 The Query Layer abstracts away receiving trustless data from The Graph decentralized network back on-chain in the form of withdraws, swaps, and other on-chain settlement which are executed on the Gelato Network. User Functionality \u00b6 Users looking to engage in the following areas can utilize the Query Layer to receive trustless data: MEV, predictions, analytics, monitoring, etc. These are just a few examples of users that might have a financial or data-driven incentive to query The Graph Network. We believe bringing a financial use case to data networks will help them flourish in the long-run. If you believe you have a decentralized network where we can host our API for validating data from The Graph, please reach out to us via Twitter or Discord. Production Requirements \u00b6 Trustless data is an absolute requirement in creating a non-custodial trustless exchange where users can coordinate on-chain actions together. Likely we will have to build out our own data validation layer in an effort to dispute either data that is indexed incorrectly or query results that are found to be invalid. This will effectively slash bad actors on The Graph Network and prevent our Execution Layer from acting on invalid data.","title":"Database Query"},{"location":"intro/layers/query/#database-query","text":"","title":"Database Query"},{"location":"intro/layers/query/#what-it-does","text":"The query layer resolves the trustless interactions between the Execution Layer (Gelato Network) and the Data Layer (The Graph Network) and ensures data has been properly validated prior to initiating any transactions on-chain. This layer is still under heavy construction and is the primary blocker for creating a fully trustless execution loop comprised of on-chain and off-chain components. Example graph LR A[User] -->|API Call| B{{Query Layer}}; B -->|Query Subgraph| C[Decentralized Node Query]; C -->|valid zkSnark?| D[return response]; C -->|invalid zkSnark?| E[Submit Dispute]; E -->|Retry| B;","title":"What It Does"},{"location":"intro/layers/query/#abstraction","text":"The Query Layer abstracts away receiving trustless data from The Graph decentralized network back on-chain in the form of withdraws, swaps, and other on-chain settlement which are executed on the Gelato Network.","title":"Abstraction"},{"location":"intro/layers/query/#user-functionality","text":"Users looking to engage in the following areas can utilize the Query Layer to receive trustless data: MEV, predictions, analytics, monitoring, etc. These are just a few examples of users that might have a financial or data-driven incentive to query The Graph Network. We believe bringing a financial use case to data networks will help them flourish in the long-run. If you believe you have a decentralized network where we can host our API for validating data from The Graph, please reach out to us via Twitter or Discord.","title":"User Functionality"},{"location":"intro/layers/query/#production-requirements","text":"Trustless data is an absolute requirement in creating a non-custodial trustless exchange where users can coordinate on-chain actions together. Likely we will have to build out our own data validation layer in an effort to dispute either data that is indexed incorrectly or query results that are found to be invalid. This will effectively slash bad actors on The Graph Network and prevent our Execution Layer from acting on invalid data.","title":"Production Requirements"},{"location":"intro/layers/user-interaction/","text":"User Interaction \u00b6 What It Does \u00b6 This is the layer which users will interact with directly to request performing any action on assets held in DCEX contracts. It contains a set of Smart Contracts that, at their most basic level, provide a way for a user to emit a given event. In more advanced cases, it can be considered a hybrid contract, where an external user can interact with the liquidity inside DCEX directly without having to perform a deposit or withdraw. Ultimately, an event will still be emitted such that any changes can take effect in the Core ERC20 Subgraph. function transfer ( address transferToken , uint256 transferAmount , address receiver ) external override { address sender = msg.sender ; emit TransferRequest ( sender , transferToken , transferAmount , receiver ); } Abstraction \u00b6 Since funds are being stored in a common contract between users, and funds can be spent by modules, certain EIP standard functions such as Transfer are abstracted away from during internal transactions (i.e. within the Subgraph). Let's take for example an ERC20 transfer to your friend: Example Standard DCEX graph LR A[User] -->|Contract call| B{ERC20.transfer}; B -->|Update Contract Storage| C(( -sender Balance<br/>+receiver Balance)); C --> D[return true]; graph LR A[User] -->|Contract call| B{Core.transfer}; B -->|Emits Event| C{{Subgraph Ingestion}}; C -->|Updates Subgraph Data| D[(<br/>-sender Balance<br/>+receiver Balance)]; Normally a user with a wallet would call to the ERC20 transfer(address dest, uint256 amount) method and use up about 30,000-60,000 gas units. In the case DCEX, if a user wants to transfer ERC20 token internally, they would call to the DCEX ERC20 Core contract's transfer(address token, uint256 amount, address receiver) method, consuming approximately 24,000-26,000 gas units. Since funds are local, there is no need to execute any code on-chain other than the event stating the action. The Ingestion Layer will handle rassigning balances as needed. Taking this to the protocol level, we can imagine a DCEX user interacting with a Module like GroupSwap, which allows users to pool gas together for on-chain swaps. Instead of a user calling to the ERC20 contract's approve() method and the DEX contract's swap method, they can call to the relevant Module contract's groupSwap() function. Example Standard DCEX GroupSwap Module graph TD A[User] -->|Contract call| B{DEX.swap}; B -->|Transfer Token In| C[DEX Processes Swap]; C -->|Transfer Token Out| D[return true]; graph TD A[User] -->|Contract call| B{GroupSwap.swap}; B -->|Emits Event| C{{Subgraph Ingestion}}; B --> G[Reserve Token]; C -->|Updates Subgraph Data| D[(<br/>Open Order<br/>Update Group)]; E[Group Executes] --> F[Token is reallocated to user]; Each request for the GroupSwap module consumes approximately 25,000-27,000 gas units. The amount of gas units consumed by a request to a Module can and will vary based on the amount of data emitted. The DCEX user doesn't need to perform an approve() , because the groupSwap() function calls to the Core contract's reserveToken() function. In this design, reservations can be seen as approvals, where a reservation is defined by a user calling to a module which then calls to the Core ERC20 contract to reserve or unreserve the token. User Functionality \u00b6 Any actions a user will perform is through a contract call to the Core or any authorized Module. For info on active Modules and what each function does in detail, see the developer docs. [LINK TO MODULE/DEVELOPER DOCS] Production Requirements \u00b6 AUDITS REQUIRED This layer should be production ready; there are not any major differences between these contracts and any other protocol's contracts'.","title":"User Interaction"},{"location":"intro/layers/user-interaction/#user-interaction","text":"","title":"User Interaction"},{"location":"intro/layers/user-interaction/#what-it-does","text":"This is the layer which users will interact with directly to request performing any action on assets held in DCEX contracts. It contains a set of Smart Contracts that, at their most basic level, provide a way for a user to emit a given event. In more advanced cases, it can be considered a hybrid contract, where an external user can interact with the liquidity inside DCEX directly without having to perform a deposit or withdraw. Ultimately, an event will still be emitted such that any changes can take effect in the Core ERC20 Subgraph. function transfer ( address transferToken , uint256 transferAmount , address receiver ) external override { address sender = msg.sender ; emit TransferRequest ( sender , transferToken , transferAmount , receiver ); }","title":"What It Does"},{"location":"intro/layers/user-interaction/#abstraction","text":"Since funds are being stored in a common contract between users, and funds can be spent by modules, certain EIP standard functions such as Transfer are abstracted away from during internal transactions (i.e. within the Subgraph). Let's take for example an ERC20 transfer to your friend: Example Standard DCEX graph LR A[User] -->|Contract call| B{ERC20.transfer}; B -->|Update Contract Storage| C(( -sender Balance<br/>+receiver Balance)); C --> D[return true]; graph LR A[User] -->|Contract call| B{Core.transfer}; B -->|Emits Event| C{{Subgraph Ingestion}}; C -->|Updates Subgraph Data| D[(<br/>-sender Balance<br/>+receiver Balance)]; Normally a user with a wallet would call to the ERC20 transfer(address dest, uint256 amount) method and use up about 30,000-60,000 gas units. In the case DCEX, if a user wants to transfer ERC20 token internally, they would call to the DCEX ERC20 Core contract's transfer(address token, uint256 amount, address receiver) method, consuming approximately 24,000-26,000 gas units. Since funds are local, there is no need to execute any code on-chain other than the event stating the action. The Ingestion Layer will handle rassigning balances as needed. Taking this to the protocol level, we can imagine a DCEX user interacting with a Module like GroupSwap, which allows users to pool gas together for on-chain swaps. Instead of a user calling to the ERC20 contract's approve() method and the DEX contract's swap method, they can call to the relevant Module contract's groupSwap() function. Example Standard DCEX GroupSwap Module graph TD A[User] -->|Contract call| B{DEX.swap}; B -->|Transfer Token In| C[DEX Processes Swap]; C -->|Transfer Token Out| D[return true]; graph TD A[User] -->|Contract call| B{GroupSwap.swap}; B -->|Emits Event| C{{Subgraph Ingestion}}; B --> G[Reserve Token]; C -->|Updates Subgraph Data| D[(<br/>Open Order<br/>Update Group)]; E[Group Executes] --> F[Token is reallocated to user]; Each request for the GroupSwap module consumes approximately 25,000-27,000 gas units. The amount of gas units consumed by a request to a Module can and will vary based on the amount of data emitted. The DCEX user doesn't need to perform an approve() , because the groupSwap() function calls to the Core contract's reserveToken() function. In this design, reservations can be seen as approvals, where a reservation is defined by a user calling to a module which then calls to the Core ERC20 contract to reserve or unreserve the token.","title":"Abstraction"},{"location":"intro/layers/user-interaction/#user-functionality","text":"Any actions a user will perform is through a contract call to the Core or any authorized Module. For info on active Modules and what each function does in detail, see the developer docs. [LINK TO MODULE/DEVELOPER DOCS]","title":"User Functionality"},{"location":"intro/layers/user-interaction/#production-requirements","text":"AUDITS REQUIRED This layer should be production ready; there are not any major differences between these contracts and any other protocol's contracts'.","title":"Production Requirements"}]}